<!DOCTYPE html>
<html lang>
  <head><meta name="generator" content="Hexo 3.9.0">
    
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width,user-scalable=no,initial-scale=1,minimum-scale=1,maximum-scale=1">


<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">



  <meta name="description" content="Redis Clsuter">




  <meta name="keywords" content="Redis,">





  <link rel="alternate" href="/default" title="Illusory">




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=1.1">



<link rel="canonical" href="http://yaoper.github.io/2020/04/14/Redis-Clsuter/">


<meta name="description" content="Redis 缓存作为使用最多的缓存工具被各大厂商争相使用。通常我们会使用单体的 Redis 应用作为缓存服务，为了保证其高可用还会使用主从模式（Master-Slave），又或者是读写分离的设计。 但是当缓存数据量增加以后，无法用单体服务器承载缓存服务时，就需要对缓存服务进行扩展。将需要缓存的数据切分成不同的分区，将数据分区放到不同的服务器中，用分布式的缓存来承载高并发的缓存访问。恰好 Redi">
<meta name="keywords" content="Redis">
<meta property="og:type" content="article">
<meta property="og:title" content="Redis Clsuter">
<meta property="og:url" content="http://yaoper.github.io/2020/04/14/Redis-Clsuter/index.html">
<meta property="og:site_name" content="Illusory">
<meta property="og:description" content="Redis 缓存作为使用最多的缓存工具被各大厂商争相使用。通常我们会使用单体的 Redis 应用作为缓存服务，为了保证其高可用还会使用主从模式（Master-Slave），又或者是读写分离的设计。 但是当缓存数据量增加以后，无法用单体服务器承载缓存服务时，就需要对缓存服务进行扩展。将需要缓存的数据切分成不同的分区，将数据分区放到不同的服务器中，用分布式的缓存来承载高并发的缓存访问。恰好 Redi">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/yaoper/image-bucket/20200405132032.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/yaoper/image-bucket/20200405133954.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/yaoper/image-bucket/20200405141431.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/yaoper/image-bucket/20200405141600.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/yaoper/image-bucket/20200405142147.jpg">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/yaoper/image-bucket/20200405142533.jpg">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/yaoper/image-bucket/20200405145020.jpg">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/yaoper/image-bucket/20200405145403.jpg">
<meta property="og:updated_time" content="2020-04-14T03:55:18.700Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Redis Clsuter">
<meta name="twitter:description" content="Redis 缓存作为使用最多的缓存工具被各大厂商争相使用。通常我们会使用单体的 Redis 应用作为缓存服务，为了保证其高可用还会使用主从模式（Master-Slave），又或者是读写分离的设计。 但是当缓存数据量增加以后，无法用单体服务器承载缓存服务时，就需要对缓存服务进行扩展。将需要缓存的数据切分成不同的分区，将数据分区放到不同的服务器中，用分布式的缓存来承载高并发的缓存访问。恰好 Redi">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/yaoper/image-bucket/20200405132032.png">


<link rel="stylesheet" type="text/css" href="/css/style.css?v=1.1">
<link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet">





<script type="text/javascript">
  var themeConfig = {
    fancybox: {
      enable: false
    },
  };
</script>




  



    <title> Redis Clsuter - Illusory </title>
  </head>

  <body>
    <div id="page">
      <header id="masthead"><div class="site-header-inner">
    <h1 class="site-title">
        <a href="/." class="logo">Illusory</a>
    </h1>

    <nav id="nav-top">
        
            <ul id="menu-top" class="nav-top-items">
                
                    <li class="menu-item">
                        <a href="/archives">
                            
                            
                                Archives
                            
                        </a>
                    </li>
                
                    <li class="menu-item">
                        <a href="/about">
                            
                            
                                About
                            
                        </a>
                    </li>
                
            </ul>
        
  </nav>
</div>

      </header>
      <div id="content">
        
    <div id="primary">
        
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          Redis Clsuter
        
      </h1>

      <time class="post-time">
          Apr 14 2020
      </time>
    </header>



    
            <div class="post-content">
            <p> Redis 缓存作为使用最多的缓存工具被各大厂商争相使用。通常我们会使用单体的 Redis 应用作为缓存服务，为了保证其高可用还会使用主从模式（Master-Slave），又或者是读写分离的设计。 但是当缓存数据量增加以后，无法用单体服务器承载缓存服务时，就需要对缓存服务进行扩展。将需要缓存的数据切分成不同的分区，将数据分区放到不同的服务器中，用分布式的缓存来承载高并发的缓存访问。恰好 Redis Cluster 方案刚好支持这部分功能。</p>
<h3 id="1-Reids-Cluster实现数据分区"><a href="#1-Reids-Cluster实现数据分区" class="headerlink" title="1. Reids Cluster实现数据分区"></a>1. Reids Cluster实现数据分区</h3><p>分布式数据库要解决的问题就是将整块数据按照规则分配到多个缓存节点，解决的是单个缓存节点处理数据量大的问题。如果要将这些数据进行拆分，并且存放必须要有一个算法。例如：哈希算法和哈希一致性算法，这是比较经典的算法。</p>
<p>Redis Cluster采用的是虚拟槽分区算法，这个槽（slot）是用来存放缓存信息的单位，在Redis中将存储空间分成16384(2^14)个槽，也就是说Redis Cluster槽的范围是0~16383。</p>
<p>缓存信息通常是用Key-Value的方式来存放的，在存储信息的时候，集群会对Key进行CRC16检验并对16384取模。（Slot=CRC16(key)%18383）。得到的结果就是Key-Value要放入的槽，从而实现自动分割数据到不同的节点上。然后再将这些槽分配到不同的缓存节点中保存。</p>
<p> <img src="https://cdn.jsdelivr.net/gh/yaoper/image-bucket/20200405132032.png" alt="redis集群数据分片"></p>
<p>如图所示，假如有三个缓存节点分别是Node1、Node2、Node3。Redis Cluster将存放缓存数据的槽分别放入这三个节点中：</p>
<ul>
<li>Node1存放的是0~5000 Slot的数据</li>
<li>Node2存放的是5001~10000 Slot的数据</li>
<li>Node3存放的是10001~16834 Slot的数据</li>
</ul>
<p>此时Redis Client需要根据一个Key获取对应的Value的数据，首先用过CRC16(key)%16384计算出Slot的值，假如是Slot=5002。那么将这个数据就传给Redis Cluster，集群接受到以后会到一个对照表中查找Slot=5002属于哪个缓存节点。发现属于Node2，于是就顺着红线的方向调用缓存节点2中存放的Key-Value的内容并且返回给Redis Client。</p>
<h3 id="2-分布式缓存节点之间的通信"><a href="#2-分布式缓存节点之间的通信" class="headerlink" title="2. 分布式缓存节点之间的通信"></a>2. 分布式缓存节点之间的通信</h3><p>Redis Clusterd的虚拟槽算法解决了数据拆分和存放的问题，接来下我们就看一下集群环境下存放缓存数据的节点之间是如何通信的。</p>
<p>缓存节点中存放着缓存的数据，在集群环境下，缓存节点会被分配到一台或者多台服务器上。</p>
<p><img src="https://cdn.jsdelivr.net/gh/yaoper/image-bucket/20200405133954.png" alt="新上线的缓存节点2和缓存节点1之间的通信"></p>
<p>上图是新上线的缓存节点2与已经存在的缓存节点1之间的通信过程，新加入的节点会通过<code>Gossip</code>协议向老节点发出一个<strong>Meet消息</strong>。收到消息以后，缓存节点1会回复一个<strong>Pong消息</strong>。此时，缓存节点2会定期给缓存节点1一个<strong>Ping消息</strong>，同样缓存节点1每次也会回复一个<strong>Pong消息</strong>。在Redis Cluster中缓存节点之间是通过Gossip协议进行通信的。节点之间通信的目的是为了维护节点之间的元数据信息，这个元数据就是每个节点包含哪些数据，是否出现故障。节点之间通过Gossip协议不断相互交互这些信息，就好像是一群人在村口八卦，没过多久每个节点就知道其他所有节点的情况了，这个情况就是节点的元数据。</p>
<p>整个传输过程大致分为以下几点：</p>
<ul>
<li>Redis Cluster 的每个缓存节点都会开通一个独立的 TCP 通道，用于和其他节点通讯。</li>
<li>有一个节点定时任务，每隔一段时间会从系统中选出“发送节点”。这个“发送节点”按照一定频率，例如：每秒 5 次，随机向最久没有通讯的节点发起 Ping 消息。</li>
<li>接受到 Ping 消息的节点会使用 Pong 消息向“发送节点”进行回复。</li>
</ul>
<p>从类型上来说消息分为四种，分别是：</p>
<ul>
<li><strong>Meet 消息，</strong>用于通知新节点加入。就好像上面例子中提到的新节点上线会给老节点发送 Meet 消息，表示有“新成员”加入。</li>
<li><strong>Ping 消息，</strong>这个消息使用得最为频繁，该<strong>*<u>消息中封装了自身节点和其他节点的状态数据</u>*</strong>，有规律地发给其他节点。</li>
<li><strong>Pong 消息，</strong>在接受到 Meet 和 Ping 消息以后，也将自己的数据状态发给对方。同时也可以对集群中所有的节点发起广播，告知大家的自身状态。</li>
<li><strong>Fail 消息，</strong>如果一个节点下线或者挂掉了，会向集群中广播这个消息。</li>
</ul>
<h3 id="3-请求分布式缓存的路由"><a href="#3-请求分布式缓存的路由" class="headerlink" title="3. 请求分布式缓存的路由"></a>3. 请求分布式缓存的路由</h3><p>对内来说，分布式缓存的节点通过Gossip协议相互发送消息，为了保证节点之间相互了解对象的情况；那么对外来说，一个Redis Client如果通过分布式节点获取数据呢？这就是分布式缓存的路由要解决的问题了。</p>
<p>Gossip协议会将每个节点管理的Slot信息发送给其他节点，其中用到了unsigned char myslots[CLUSTER_SLOTS/8]这样一个数组存放每个节点的Slot信息。myslots 属性是一个二进制位数组（bit array），其中 CLUSTER_SLOTS 为 16384。这个数组的长度为 16384/8=2048 个字节，由于每个字节包含 8 个 bit 位（二进制位），所以共包含 16384 个 bit，也就是 16384 个二进制位。每个节点用 bit 来标识自己是否拥有某个槽的数据。 </p>
<p><img src="https://cdn.jsdelivr.net/gh/yaoper/image-bucket/20200405141431.png" alt="二进制数组存放槽信息"></p>
<p> 0、1、2 三个数组下标就表示 0、1、2 三个槽，如果对应的二进制值是 1，表示该节点负责存放 0、1、2 三个槽的数据。同理，后面的数组下标位 0 就表示该节点不负责存放对应槽的数据。用二进制存放的优点是，判断的效率高，例如对于编号为 1 的槽，节点只要判断序列的第二位，时间复杂度为 O（1）。 </p>
<p> 当收到发送节点的节点槽信息以后，接受节点会将这些信息保存到本地的 Cluster State 的结构中，其中 Slots 的数组就是存放每个槽对应哪些节点信息。 </p>
<p> <img src="https://cdn.jsdelivr.net/gh/yaoper/image-bucket/20200405141600.png" alt="Cluster Status结构以及槽与节点的对应"></p>
<p>Cluster State 中保存的 Slots 数组中每个下标对应一个槽，每个槽信息中对应一个 Cluster Node 也就是缓存的节点。 这些节点会对应一个实际存在的 Redis 缓存服务，包括 IP 和 Port 的信息。Redis Cluster 的通讯机制实际上保证了每个节点都有其他节点和槽数据的对应关系。Redis 的客户端无论访问集群中的哪个节点都可以路由到对应的节点上，因为每个节点都有一份 Cluster State，它记录了所有槽和节点的对应关系。</p>
<p> 下图是Redis Client通过路由调用缓存节点的步骤：</p>
<p><img src="https://cdn.jsdelivr.net/gh/yaoper/image-bucket/20200405142147.jpg" alt="无迁移的缓存节点数据查询"></p>
<p> Redis Client 通过 CRC16(key)%16383 计算出 Slot 的值，发现需要找“缓存节点 1”读/写数据，但是由于缓存数据迁移或者其他原因导致这个对应的 Slot 的数据被迁移到了“缓存节点 2”上面。 那么这个时候 Redis 客户端就无法从“缓存节点 1”中获取数据了。但是由于“缓存节点 1”中保存了所有集群中缓存节点的信息，因此它知道这个 Slot 的数据在“缓存节点 2”中保存，因此向 Redis 客户端发送了一个 MOVED 的重定向请求。这个请求告诉其应该访问的“缓存节点 2”的地址。Redis 客户端拿到这个地址，继续访问“缓存节点 2”并且拿到数据。数据 Slot 从“缓存节点 1”已经迁移到“缓存节点 2”了，那么客户端可以直接找“缓存节点 2”要数据。 </p>
<p>如果两个缓存节点正在做节点的数据迁移，这个时候Redis Client请求缓存数据的步骤又是怎么样的呢？</p>
<p><img src="https://cdn.jsdelivr.net/gh/yaoper/image-bucket/20200405142533.jpg" alt="数据正在迁移的访问步骤"></p>
<p>edis 客户端向“缓存节点 1”发出请求，此时“缓存节点 1”正向“缓存节点 2”迁移数据，如果没有命中对应的 Slot，它会返回客户端一个 ASK 重定向请求并且告诉“缓存节点 2”的地址。 客户端向“缓存节点 2”发送 Asking 命令，询问需要的数据是否在“缓存节点 2”上，“缓存节点 2”接到消息以后返回数据是否存在的结果。 </p>
<h3 id="4-缓存节点的扩容和缩容"><a href="#4-缓存节点的扩容和缩容" class="headerlink" title="4. 缓存节点的扩容和缩容"></a>4. 缓存节点的扩容和缩容</h3><p>分布式缓存由于每个节点中保存着槽数据，因此当缓存节点出现变动时，这些槽数据会根据对应的虚拟槽算法被迁移到其他缓存节点上。</p>
<p><img src="https://cdn.jsdelivr.net/gh/yaoper/image-bucket/20200405145020.jpg" alt="扩容"></p>
<p>集群中本来存在“缓存节点 1”和“缓存节点 2”，此时“缓存节点 3”上线了并且加入到集群中。此时根据虚拟槽的算法，“缓存节点 1”和“缓存节点 2”中对应槽的数据会应该新节点的加入被迁移到“缓存节点 3”上面。针对节点扩容，新建立的节点需要运行在集群模式下，因此新建节点的配置最好与集群内其他节点配置保持一致。 新节点加入到集群的时候，作为孤儿节点是没有和其他节点进行通讯的。因此，其会采用 cluster meet 命令加入到集群中。在集群中任意节点执行 cluster meet 命令让新节点加入进来。假设新节点是 192.168.1.1 5002，老节点是 192.168.1.1 5003，那么运行以下命令将新节点加入到集群中。  </p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">192.168.1.1 5003&gt; cluster meet 192.168.1.1 5002</span><br></pre></td></tr></table></figure>

<p>这个是由老节点发起的，有点老成员欢迎新成员加入的意思。新节点刚刚建立没有建立槽对应的数据，也就是说没有缓存任何数据。</p>
<p> 如果这个节点是主节点，需要对其进行槽数据的扩容；如果这个节点是从节点，就需要同步主节点上的数据。总之就是要同步数据。</p>
<p> <img src="https://cdn.jsdelivr.net/gh/yaoper/image-bucket/20200405145403.jpg" alt="节点迁移槽数据的过程"></p>
<p> 上图是客户端发起节点之间的槽数据迁移，数据从源节点往目标节点迁移： </p>
<ul>
<li><p>客户端对目标节点发起准备导入槽数据的命令，让目标节点准备好导入槽数据。这里使用 cluster setslot {slot} importing {sourceNodeId} 命令。</p>
</li>
<li><p>之后对源节点发起送命令，让源节点准备迁出对应的槽数据。使用命令 cluster setslot {slot} importing {sourceNodeId}。</p>
</li>
<li><p>此时源节点准备迁移数据了，在迁移之前把要迁移的数据获取出来。通过命令 cluster getkeysinslot {slot} {count}。Count 表示迁移的 Slot 的个数。</p>
</li>
<li><p>然后在源节点上执行，migrate {targetIP} {targetPort} “” 0 {timeout} keys{keys} 命令，把获取的键通过流水线批量迁移到目标节点。</p>
</li>
<li><p>重复 3 和 4 两步不断将数据迁移到目标节点。目标节点获取迁移的数据。</p>
</li>
<li><p>完成数据迁移以后目标节点，通过 cluster setslot {slot} node {targetNodeId} 命令通知对应的槽被分配到目标节点，并且广播这个信息给全网的其他主节点，更新自身的槽节点对应表。</p>
<p>缩容和扩容操作刚好相反，不同的是在缩容的过程中需要通知全网的其他节点忘记自己，此时通过命令 cluster forget{downNodeId} 通知其他的节点。 当节点收到 forget 命令以后会将这个下线节点放到仅用列表中，那么之后就不用再向这个节点发送 Gossip 的 Ping 消息了。不过这个仅用表的超时时间是 60 秒，超过了这个时间，依旧还会对这个节点发起 Ping 消息。不过可以使用 redis-trib.rb del-node{host:port} {donwNodeId} 命令帮助我们完成下线操作。</p>
</li>
</ul>
<h3 id="5-故障发现和恢复"><a href="#5-故障发现和恢复" class="headerlink" title="5. 故障发现和恢复"></a>5. 故障发现和恢复</h3><p>针对下线故障来说有两种下线的确定方式： </p>
<p><strong>主观下线：</strong>当节点 1 向节点 2 例行发送 Ping 消息的时候，如果节点 2 正常工作就会返回 Pong 消息，同时会记录节点 1 的相关信息。 同时接受到 Pong 消息以后节点 1 也会更新最近一次与节点 2 通讯的时间。如果此时两个节点由于某种原因断开连接，过一段时间以后节点 1 还会主动连接节点 2，如果一直通讯失败，节点 1 中就无法更新与节点 2 最后通讯时间了。此时节点 1 的定时任务检测到与节点 2 最好通讯的时间超过了 cluster-node-timeout 的时候，就会更新本地节点状态，把节点 2 更新为主观下线。这里的 cluster-node-timeout 是节点挂掉被发现的超时时间，如果超过这个时间还没有获得节点返回的 Pong 消息就认为该节点挂掉了。这里的主观下线指的是，节点 1 主观的认为节点 2 没有返回 Pong 消息，因此认为节点 2 下线。只是节点 1 的主观认为，有可能是节点 1 与节点 2 之间的网络断开了，但是其他的节点依旧可以和节点 2 进行通讯，因此主观下线并不能代表某个节点真的下线了。</p>
<p> <strong>客观下线：</strong>由于 Redis Cluster 的节点不断地与集群内的节点进行通讯，下线信息也会通过 Gossip 消息传遍所有节点。因此集群内的节点会不断收到下线报告，当半数以上持有槽的主节点标记了某个节点是主观下线时，便会触发客观下线的流程。也就是说当集群内的半数以上的主节点，认为某个节点主观下线了，才会启动这个流程。<strong>*<u>这个流程有一个前提，就是直针对主节点，如果是从节点就会忽略</u>*</strong>。也就是说集群中的节点每次接受到其他节点的主观下线是都会做以下的事情。</p>
<p> 将主观下线的报告保存到本地的 ClusterNode 的结构中，并且针对主观下线报告的时效性进行检查，如果超过 cluster-node-timeout*2 的时间，就忽略这个报告。否则就记录报告内容，并且比较被标记下线的主观节点的报告数量大于等于持有槽的主节点数量的时候，将其标记为客观下线。同时向集群中广播一条 Fail 消息，通知所有的节点将故障节点标记为客观下线，这个消息指包含故障节点的 ID。此后，群内所有的节点都会标记这个节点为客观下线，通知故障节点的从节点出发故障转移的流程，也就是故障的恢复。客观下线就是整个集群中有一半的节点都认为某节点主观下线了，那么这个节点就被标记为客观下线了。 如果某个主节点被认为客观下线了，那么需要从它的从节点中选出一个节点替代主节点的位置。此时下线主节点的所有从节点都担负着恢复义务，这些从节点会定时监测主节点是否下线。</p>
<p> 一旦发现下线会走如下的恢复流程：</p>
<p> <strong>①资格检查，</strong>每个节点都会检查与主节点断开的时间。如果这个时间超过了 cluster-node-timeout*cluster-slave-validity-factor（从节点有效因子，默认为 10），那么就没有故障转移的资格。 也就是说这个从节点和主节点断开的太久了，很久没有同步主节点的数据了，不适合成为新的主节点，因为成为主节点以后其他的从节点回同步自己的数据。 </p>
<p> <strong>②触发选举，</strong>通过了上面资格的从节点都可以触发选举。但是出发选举是有先后顺序的，这里按照复制偏移量的大小来判断。 这个偏移量记录了执行命令的字节数。主服务器每次向从服务器传播 N 个字节时就会将自己的复制偏移量+N，从服务在接收到主服务器传送来的 N 个字节的命令时，就将自己的复制偏移量+N。复制偏移量越大说明从节点延迟越低，也就是该从节点和主节点沟通更加频繁，该从节点上面的数据也会更新一些，因此复制偏移量大的从节点会率先发起选举。</p>
<p> <strong>③发起选举，</strong>首先每个主节点会去更新配置纪元（clusterNode.configEpoch），这个值是不断增加的整数。 在节点进行 Ping/Pong 消息交互式也会更新这个值，它们都会将最大的值更新到自己的配置纪元中。这个值记录了每个节点的版本和整个集群的版本。每当发生重要事情的时候，例如：出现新节点，从节点精选。都会增加全局的配置纪元并且赋给相关的主节点，用来记录这个事件。更新这个值目的是，保证所有主节点对这件“大事”保持一致。大家都统一成一个配置纪元（一个整数），表示大家都知道这个“大事”了。 更新完配置纪元以后，会想群内发起广播选举的消息（FAILOVER_AUTH_REQUEST）。并且保证每个从节点在一次配置纪元中只能发起一次选举。</p>
<p> <strong>④投票选举，</strong>参与投票的只有主节点，从节点没有投票权，超过半数的主节点通过某一个节点成为新的主节点时投票完成。 如果在 cluster-node-timeout*2 的时间内从节点没有获得足够数量的票数，本次选举作废，进行第二轮选举。这里每个候选的从节点会收到其他主节点投的票。在第2步领先的从节点通常此时会获得更多的票，因为它触发选举的时间更早一些。</p>
<p> <strong>⑤当满足投票条件的从节点被选出来以后，会触发替换主节点的操作。</strong>新的主节点别选出以后，删除原主节点负责的槽数据，把这些槽数据添加到自己节点上。并且广播让其他的节点都知道这件事情，新的主节点诞生了。</p>
<h3 id="6-总结"><a href="#6-总结" class="headerlink" title="6. 总结"></a>6. 总结</h3><p>Redis Cluster通过虚拟槽的分区算法，将整块数据分配到不同的缓存节点；通过Slot和Node的对应关系让数据找到节点的位置。</p>
<p>各缓存节点通过Gossip协议进行Meet、Ping、Pong、Fail的通信，达到相互同步所有节点元数据的目的。</p>
<p>Redis Client调用缓存节点数据的时候通过Moved和Asked重定向请求找到正确的缓存节点。</p>
<p>缓存节点扩容的时候需要从新计算Slot以及完成数据迁移，缩容时的操作刚好相反。</p>
<p>集群中的故障节点下线包括主观下线和客观下线，如果是主节点下线，需要进行投票选举出主节点。</p>

            </div>
          

    
      <footer class="post-footer">
		
		<div class="post-tags">
		  
			<a href="/tags/Redis/">Redis</a>
		  
		</div>
		

        
        
  <nav class="post-nav">
    
      <a class="prev" href="/2020/04/14/Object-Header/">
        <i class="iconfont icon-left"></i>
        <span class="prev-text nav-default">Object Header</span>
        <span class="prev-text nav-mobile">Prev</span>
      </a>
    
    
      <a class="next" href="/2020/04/13/Java里面的异常/">
        <span class="next-text nav-default">Java里面的异常</span>
        <span class="prev-text nav-mobile">Next</span>
        <i class="iconfont icon-right"></i>
      </a>
    
  </nav>

        
  <div class="comments" id="comments">
    
  </div>


      </footer>
    
  </article>

    </div>

      </div>

      <footer id="colophon"><span class="copyright-year">
    
        &copy;
    
        2014 -
    
    2020
    <span class="footer-author">yaoper.</span>
    <span class="power-by">
        Powered by <a class="hexo-link" href="https://hexo.io/">Hexo</a> and <a class="theme-link" href="https://github.com/frostfan/hexo-theme-polarbear">Polar Bear</a>
    </span>
</span>

      </footer>

      <div class="back-to-top" id="back-to-top">
        <i class="iconfont icon-up"></i>
      </div>
    </div>
    


    




  
    <script type="text/javascript" src="/lib/jquery/jquery-3.1.1.min.js"></script>
  

  

    <script type="text/javascript" src="/js/src/theme.js?v=1.1"></script>
<script type="text/javascript" src="/js/src/bootstrap.js?v=1.1"></script>

  </body>
</html>
